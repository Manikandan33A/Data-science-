# -*- coding: utf-8 -*-
"""NM Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LDjgaAcBp8BmSP1M8FkFgg1TsAcHDyuk

**Upload the dataset**
"""

# Upload the Dataset
from google.colab import files
uploaded = files.upload()

"""**Load the dataset**"""

# Load the Dataset
import pandas as pd

df = pd.read_csv('stock_data.csv')
df.head()

"""**Data Exploration**"""

df.head()

"""**Check for Missing Values and Duplicates**"""

print(df.isnull().sum())
 print("Duplicate rows:", df.duplicated().sum())

"""**Visualize a Few Features**"""

import matplotlib.pyplot as plt

# Plot the closing price over time
plt.figure(figsize=(12, 6))
plt.plot(df['Close'], label='Close Price')
plt.title('Stock Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()

# You can also visualize other features like rolling mean and standard deviation
# Calculate rolling mean and standard deviation
df['Rolling Mean'] = df['Close'].rolling(window=30).mean()  # 30-day rolling mean
df['Rolling Std'] = df['Close'].rolling(window=30).std()

# Plot rolling statistics along with closing price
plt.figure(figsize=(12, 6))
plt.plot(df['Close'], label='Close Price')
plt.plot(df['Rolling Mean'], label='Rolling Mean (30 days)')
plt.plot(df['Rolling Std'], label='Rolling Std (30 days)')
plt.title('Stock Price with Rolling Statistics')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()

"""**Identify Target and Features**"""

# Load the dataset
import pandas as pd

df = pd.read_csv('stock_data.csv')
print(df.columns)

"""**Convert Categorical Columns to Numerical**"""

# Identify categorical columns
 categorical_cols = df.select_dtypes(include=['object']).columns
 print("Categorical Columns:", categorical_cols.tolist())

"""**One-Hot Encoding**"""

df_encoded = pd.get_dummies(df, drop_first=True)

"""**Feature Scaling**"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Assuming df_encoded is your DataFrame with encoded features:

# 1. Create a MinMaxScaler object
scaler = MinMaxScaler()

# 2. Select the numerical features to scale
#    (excluding the target variable if it's in

"""**Train-Test Split**"""

from sklearn.model_selection import train_test_split

# Assuming df_encoded is your DataFrame with features and target:
# and 'Close' is your target variable

# 1. Separate features (X) and target (y)
X = df_encoded.drop('Close', axis=1)  # Features (all columns except 'Close')
y = df_encoded['Close']              # Target variable ('Close')

# 2. Perform the split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Explanation of parameters:
# - X, y: Your features and target data
# - test_size: Proportion of data to include in the test split (e.g., 0.2 for 20%)

"""**Model Building**"""

# Model Building

# Import the Linear Regression model
from sklearn.linear_model import LinearRegression

# Create a Linear Regression model instance
model = LinearRegression()

# Train the model using the training data
# X_train contains your features for training
# y_train contains your target variable (Close price) for training
model.fit(X_train, y_train)

print("Model training complete.")
# You can now use this 'model' object to make predictions

"""**Evaluation**"""

# Evaluation (Simple)

from sklearn.metrics import r2_score, mean_absolute_error

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate evaluation metrics
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print the evaluation metrics
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"R-squared (R2): {r2:.2f}")

# You can still include a simple visualization
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.xlabel("Actual Close Price")
plt.ylabel("Predicted Close Price")
plt.title("Actual vs. Predicted Close Prices (Simple)")
plt.grid(True)
plt.show()

"""**Make Predictions from New Input**"""

# Sample input (replace values with any other valid values from the original dataset)
 new_student = {
    'school': 'GP',             # 'GP' or 'MS'
    'sex': 'F',                 # 'F' or 'M'
    'age': 17,                  # Integer
    'address': 'U',            # 'U' or 'R'
    'famsize': 'GT3',          # 'LE3' or 'GT3'
    'Pstatus': 'A',            # 'A' or 'T'
    'Medu': 4,                 # 0 to 4
    'Fedu': 3,                 # 0 to 4
    'Mjob': 'health',          # 'teacher', 'health', etc.
    'Fjob': 'services',
    'reason': 'course',
    'guardian': 'mother',
    'traveltime': 2,
    'studytime': 3,
    'failures': 0,
    'schoolsup': 'yes',
    'famsup': 'no',
    'paid': 'no',
    'activities': 'yes',
    'nursery': 'yes',
    'higher': 'yes',
    'internet': 'yes',
    'romantic': 'no',
    'famrel': 4,
    'freetime': 3,
    'goout': 3,
    'Dalc': 1,
    'Walc': 1,
    'health': 4,
    'absences': 2,
    'G1': 14,
 'G2': 15
 }

"""**Convert to DataFrame and Encode**"""

import pandas as pd

# 1. Convert the new input to a DataFrame
new_input_df = pd.DataFrame([new_student])  # Enclose in a list to create DataFrame

# 2. Perform one-hot encoding
# (Assuming 'df_encoded' is the DataFrame used during training)
new_input_encoded = pd.get_dummies(new_input_df)

# 3. Align columns with the training data
# (To ensure the same features are present in the new input)
new_input_encoded = new_input_encoded.reindex(columns=X_train.columns, fill_value=0)

# Now, 'new_input_encoded' is ready for prediction.

"""**Predict the Final Grade**"""

# Predict the Close Price for the new input

# Use the trained model to make a prediction
# new_input_encoded is the DataFrame representing the new data point
predicted_close_price = model.predict(new_input_encoded)

# The predict method returns an array, even for a single prediction.
# We extract the first (and only) element to get the single predicted value.
predicted_price = predicted_close_price[0]

print(f"Predicted Close Price for the new input: {predicted_price:.2f}")

"""**Deployment-Building an Interactive App**"""

!pip install streamlit
import streamlit as st
import pandas as pd
from sklearn.linear_model import LinearRegression  # Or your chosen model

# ... (Load your trained model and necessary data here) ...

# Create the Streamlit app
st.title("Stock Price Prediction App")

# Input fields for features
open_price = st.number_input("Open Price")
high_price = st.number_input("High Price")
low_price = st.number_input("Low Price")
volume = st.number_input("Volume")
# ... (Add other input fields for your features) ...

# Create a button to trigger prediction
if st.button("Predict"):
    # Create a DataFrame from the input values
    input_data = pd.DataFrame({
        "Open": [open_price],
        "High": [high_price],
        "Low": [low_price],
        "Volume": [volume],
        # ... (Include other features) ...
    })

    # Preprocess the input data (e.g., scaling) if necessary
    # ...

    # Make the prediction
    prediction = model.predict(input_data)[0]

    # Display the prediction
    st.success(f"Predicted Close Price: {prediction}")

"""**Create a Prediction Function**"""

import numpy as np

def predict_next_close(input_sequence, model, scaler, seq_length=60):
    """
    Predict the next stock closing price using a trained LSTM model.

    Parameters:
        input_sequence (list or np.array): Last `seq_length` days of closing prices.
        model (keras.Model): Trained LSTM model.
        scaler (MinMaxScaler): Scaler used for normalization.
        seq_length (int): Number of time steps used in training.

    Returns:
        float: Predicted next closing price (denormalized).
    """
    if len(input_sequence) != seq_length:
        raise ValueError(f"Input sequence must be of length {seq_length}")

    # Scale and reshape input
    scaled_sequence = scaler.transform(np.array(input_sequence).reshape(-1, 1))
    X_input = np.reshape(scaled_sequence, (1, seq_length, 1))

    # Predict
    prediction = model.predict(X_input)
    predicted_price = scaler.inverse_transform(prediction)[0][0]

    return round(predicted_price, 2)

"""**Create the Gradio Interface**"""

!pip install gradio

import gradio as gr
import numpy as np

def predict_next_close(input_sequence_str):
    """
    Takes 60 comma-separated closing prices as input and returns the next predicted price.
    """
    try:
        # Parse input string to list of floats
        input_sequence = [float(x.strip()) for x in input_sequence_str.split(',')]

        if len(input_sequence) != 60:
            return "‚ùå Please provide exactly 60 closing prices."

        # Scale and reshape
        scaled_sequence = scaler.transform(np.array(input_sequence).reshape(-1, 1))
        X_input = np.reshape(scaled_sequence, (1, 60, 1))

        # Predict
        prediction = model.predict(X_input)
        predicted_price = scaler.inverse_transform(prediction)[0][0]

        return f"üìà Predicted Next Closing Price: ‚Çπ{round(predicted_price, 2)}"

    except Exception as e:
        return f"‚ùå Error: {str(e)}"

interface = gr.Interface(
    fn=predict_next_close,
    inputs=gr.Textbox(
        lines=4,
        placeholder="Enter the last 60 closing prices, separated by commas...",
        label="Recent 60 Closing Prices"
    ),
    outputs=gr.Textbox(label="üìä Predicted Closing Price"),
    title="üìà AI Stock Price Predictor",
    description="Enter 60 consecutive closing prices to forecast the next day using an LSTM model."
)

interface.launch()